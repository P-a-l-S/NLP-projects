{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommended _system.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPAzlG+6YPoZbMVLWRYPD2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paalll/NLP-projects/blob/main/Spam%20Filetering%20System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwlm67pE_Bn1"
      },
      "source": [
        "def make_Dictionary(train_dir):\r\n",
        "    emails = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]    \r\n",
        "    all_words = []       \r\n",
        "    for mail in emails:    \r\n",
        "        with open(mail) as m:\r\n",
        "            for i,line in enumerate(m):\r\n",
        "                if i == 2:  #Body of email is only 3rd line of text file\r\n",
        "                    words = line.split()\r\n",
        "                    all_words += words\r\n",
        "    \r\n",
        "    dictionary = Counter(all_words)\r\n",
        "    list_to_remove = dictionary.keys()\r\n",
        "    for item in list_to_remove:\r\n",
        "        if item.isalpha() == False: \r\n",
        "            del dictionary[item]\r\n",
        "        elif len(item) == 1:\r\n",
        "            del dictionary[item]\r\n",
        "    dictionary = dictionary.most_common(3000)\r\n",
        "    # Paste code for non-word removal here(code snippet is given below) \r\n",
        "    return dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHUYuG4eDFlu"
      },
      "source": [
        "def extract_features(mail_dir): \r\n",
        "    files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\r\n",
        "    features_matrix = np.zeros((len(files),3000))\r\n",
        "    docID = 0;\r\n",
        "    for fil in files:\r\n",
        "      with open(fil) as fi:\r\n",
        "        for i,line in enumerate(fi):\r\n",
        "          if i == 2:\r\n",
        "            words = line.split()\r\n",
        "            for word in words:\r\n",
        "              wordID = 0\r\n",
        "              for i,d in enumerate(dictionary):\r\n",
        "                if d[0] == word:\r\n",
        "                  wordID = i\r\n",
        "                  features_matrix[docID,wordID] = words.count(word)\r\n",
        "        docID = docID + 1     \r\n",
        "    return features_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "o_KL-sQvDPvp",
        "outputId": "2d21c654-55b9-4529-8bf8-64c3b03ea725"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\r\n",
        "from sklearn.svm import SVC, NuSVC, LinearSVC\r\n",
        "\r\n",
        "# Create a dictionary of words with its frequency\r\n",
        "\r\n",
        "train_dir = 'train-mails'\r\n",
        "dictionary = make_Dictionary(train_dir)\r\n",
        "\r\n",
        "# Prepare feature vectors per training mail and its labels\r\n",
        "\r\n",
        "train_labels = np.zeros(702)\r\n",
        "train_labels[351:701] = 1\r\n",
        "train_matrix = extract_features(train_dir)\r\n",
        "\r\n",
        "# Training SVM and Naive bayes classifier\r\n",
        "\r\n",
        "model1 = MultinomialNB()\r\n",
        "model2 = LinearSVC()\r\n",
        "model1.fit(train_matrix,train_labels)\r\n",
        "model2.fit(train_matrix,train_labels)\r\n",
        "\r\n",
        "# Test the unseen mails for Spam\r\n",
        "test_dir = 'test-mails'\r\n",
        "test_matrix = extract_features(test_dir)\r\n",
        "test_labels = np.zeros(260)\r\n",
        "test_labels[130:260] = 1\r\n",
        "result1 = model1.predict(test_matrix)\r\n",
        "result2 = model2.predict(test_matrix)\r\n",
        "printconfusion_matrix(test_labels,result1)\r\n",
        "print confusion_matrix(test_labels,result2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-81d44eb5f1df>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    print confusion_matrix(test_labels,result2)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}